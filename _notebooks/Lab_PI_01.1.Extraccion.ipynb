{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 851,
     "status": "ok",
     "timestamp": 1701292892075,
     "user": {
      "displayName": "Miguel Dallanegra",
      "userId": "11883577213235347490"
     },
     "user_tz": 180
    },
    "id": "40_IgsLW5RaJ"
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import re\n",
    "import ast\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracción de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descomprimir y Reconvertir Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Archivo steam_games.json.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direccion del archivo comprimido\n",
    "steam_games_content= '../_src/steam_games.json.gz'\n",
    "# Cargar directamente el archivo JSON comprimido en un DataFrame\n",
    "steam_games_dataset = pd.read_json(steam_games_content, compression='gzip', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos el tamaño del dataframe original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El DataFrame tiene 120445 filas y 13 columnas.\n"
     ]
    }
   ],
   "source": [
    "print(f\"El DataFrame tiene {steam_games_dataset.shape[0]} filas y {steam_games_dataset.shape[1]} columnas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos filas nulas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_games_dataset.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos el tamaño del dataframe después de la eliminacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El DataFrame tiene 22530 filas y 13 columnas.\n"
     ]
    }
   ],
   "source": [
    "print(f\"El DataFrame tiene {steam_games_dataset.shape[0]} filas y {steam_games_dataset.shape[1]} columnas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constatamos tipos de datos y forma de la tabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publisher        object\n",
      "genres           object\n",
      "app_name         object\n",
      "title            object\n",
      "url              object\n",
      "release_date     object\n",
      "tags             object\n",
      "reviews_url      object\n",
      "specs            object\n",
      "price            object\n",
      "early_access    float64\n",
      "id              float64\n",
      "developer        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(steam_games_dataset.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probar si puedo eliminar duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0p/tsl8rn8x1vs7k18zw9s6dh0r0000gn/T/ipykernel_12286/2613242174.py:9: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  steam_games_dataset = steam_games_dataset.applymap(lambda x: tuple(x) if isinstance(x, eval(palabra_entre_comillas.group(1))) else x)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0p/tsl8rn8x1vs7k18zw9s6dh0r0000gn/T/ipykernel_12286/2613242174.py:13: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  steam_games_dataset = steam_games_dataset.applymap(lambda x: eval(palabra_entre_comillas.group(1))(x) if isinstance(x, tuple) else x)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    #Elimina duplicados\n",
    "    steam_games_dataset.drop_duplicates(inplace=True)\n",
    "except TypeError as error: \n",
    "    # Si el tipo de la columna no es el que puede eliminar duplicados, \n",
    "    # lo reconoce, lo modifica a tuplas, elimina duplicados y devuelve el tipo inicial\n",
    "    palabra_entre_comillas = re.search(r\"'(.*?)'\", str(error))\n",
    "    # Convertir la columna con listas en tuplas\n",
    "    steam_games_dataset = steam_games_dataset.applymap(lambda x: tuple(x) if isinstance(x, eval(palabra_entre_comillas.group(1))) else x)\n",
    "    #Elimina duplicados\n",
    "    steam_games_dataset.drop_duplicates(inplace=True)\n",
    "    # Revertir el dataframe de tuplas a listas después de eliminar duplicados\n",
    "    steam_games_dataset = steam_games_dataset.applymap(lambda x: eval(palabra_entre_comillas.group(1))(x) if isinstance(x, tuple) else x)\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error: {e}. Continúa con los trabajos sobre el dataframe.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos el tamaño del dataframe después eliminar duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El DataFrame tiene 22530 filas y 13 columnas.\n"
     ]
    }
   ],
   "source": [
    "print(f\"El DataFrame tiene {steam_games_dataset.shape[0]} filas y {steam_games_dataset.shape[1]} columnas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardado del DataFrame a un archivo convertido a .parquet para comodidad en el trabajo de ETL y EDA posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_games_dataset['price'] = steam_games_dataset['price'].astype(str) # Se hace porque da error de tipo al guardar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el df en un archivo parquet\n",
    "steam_games_dataset.to_parquet('../_data/01_steam_games.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Archivo users_items.json.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direccion del archivo\n",
    "users_items_content= '../_src/users_items.json.gz'\n",
    "\n",
    "# Lista para guardar cada fila\n",
    "lista_users_items = []\n",
    "\n",
    "# Descomprimir el archivo y cargar JSON línea por línea\n",
    "with gzip.open(users_items_content, 'rb') as users_items_gzip:\n",
    "    for linea in users_items_gzip:\n",
    "        try:\n",
    "            # Decodifica la línea y agrega el objeto a la lista\n",
    "            fila = ast.literal_eval(linea.decode('utf-8'))\n",
    "            lista_users_items.append(fila)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error al cargar la línea: {linea}. Error: {e}\")\n",
    "\n",
    "# Convertir la lista a DataFrame\n",
    "users_items_dataset = pd.DataFrame(lista_users_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos el tamaño del dataframe original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El DataFrame tiene 88310 filas y 5 columnas.\n"
     ]
    }
   ],
   "source": [
    "print(f\"El DataFrame tiene {users_items_dataset.shape[0]} filas y {users_items_dataset.shape[1]} columnas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos filas nulas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_items_dataset.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos el tamaño del dataframe después de la eliminacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El DataFrame tiene 88310 filas y 5 columnas.\n"
     ]
    }
   ],
   "source": [
    "print(f\"El DataFrame tiene {users_items_dataset.shape[0]} filas y {users_items_dataset.shape[1]} columnas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constatamos tipos de datos y forma de la tabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id        object\n",
      "items_count     int64\n",
      "steam_id       object\n",
      "user_url       object\n",
      "items          object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(users_items_dataset.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probar si puedo eliminar duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No se pudo eliminar duplicados porque el dataframe es de tipo list, intentar mas adelante.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    users_items_dataset.drop_duplicates(inplace=True)\n",
    "except TypeError as error: \n",
    "    palabra_entre_comillas = re.search(r\"'(.*?)'\", str(error))\n",
    "    print(f\"No se pudo eliminar duplicados porque el dataframe es de tipo {palabra_entre_comillas.group(1)}, intentar mas adelante.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error: {e}. Continúa con los trabajos sobre el dataframe.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos el tamaño del dataframe después de la eliminacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El DataFrame tiene 88310 filas y 5 columnas.\n"
     ]
    }
   ],
   "source": [
    "print(f\"El DataFrame tiene {users_items_dataset.shape[0]} filas y {users_items_dataset.shape[1]} columnas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardado del DataFrame a un archivo convertido a .parquet para ahorro de espacio y comodidad en el trabajo de ETL y EDA posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar DataFrame en un archivo Parquet\n",
    "users_items_dataset.to_parquet('../_data/01_users_items.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Archivo user_reviews.json.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direccion del archivo\n",
    "user_reviews_content= '../_src/user_reviews.json.gz'\n",
    "\n",
    "# Lista para guardar cada fila\n",
    "lista_user_reviews = []\n",
    "\n",
    "# Descomprimir el archivo y cargar JSON línea por línea\n",
    "with gzip.open(user_reviews_content, 'rb') as user_reviews_gzip:\n",
    "    for linea in user_reviews_gzip:\n",
    "        try:\n",
    "            # Decodifica la línea y agrega el objeto a la lista\n",
    "            fila = ast.literal_eval(linea.decode('utf-8'))\n",
    "            lista_user_reviews.append(fila)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error al cargar la línea: {linea}. Error: {e}\")\n",
    "\n",
    "# Convertir la lista a DataFrame\n",
    "user_reviews_dataset = pd.DataFrame(lista_user_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos el tamaño del dataframe original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El DataFrame tiene 25799 filas y 3 columnas.\n"
     ]
    }
   ],
   "source": [
    "print(f\"El DataFrame tiene {user_reviews_dataset.shape[0]} filas y {user_reviews_dataset.shape[1]} columnas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos filas nulas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_reviews_dataset.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos el tamaño del dataframe después de la eliminacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El DataFrame tiene 25799 filas y 3 columnas.\n"
     ]
    }
   ],
   "source": [
    "print(f\"El DataFrame tiene {user_reviews_dataset.shape[0]} filas y {user_reviews_dataset.shape[1]} columnas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constatamos tipos de datos y forma de la tabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id     object\n",
      "user_url    object\n",
      "reviews     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(user_reviews_dataset.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probar si puedo eliminar duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No se pudo eliminar duplicados porque el dataframe es de tipo list, intentar mas adelante.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    user_reviews_dataset.drop_duplicates(inplace=True)\n",
    "except TypeError as error: \n",
    "    palabra_entre_comillas = re.search(r\"'(.*?)'\", str(error))\n",
    "    print(f\"No se pudo eliminar duplicados porque el dataframe es de tipo {palabra_entre_comillas.group(1)}, intentar mas adelante.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ocurrió un error: {e}. Continúa con los trabajos sobre el dataframe.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos el tamaño del dataframe después de la eliminacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El DataFrame tiene 25799 filas y 3 columnas.\n"
     ]
    }
   ],
   "source": [
    "print(f\"El DataFrame tiene {user_reviews_dataset.shape[0]} filas y {user_reviews_dataset.shape[1]} columnas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardado del DataFrame a un archivo convertido a .parquet para ahorro de espacio y comodidad en el trabajo de ETL y EDA posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar DataFrame en un archivo Parquet\n",
    "user_reviews_dataset.to_parquet('../_data/01_user_reviews.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se eligen guardar todos los dataframes en formato paquet ya que este es muy liviano y eficiente para manejar datos. Además ayudara en subsiguientes trabajos y finalmente subirlos a FastAPI y render."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMHA6gysyw2Wvf8s1BSCbH6",
   "mount_file_id": "1F_XADlQEt0uqeXIRDyyGcMn700hYHkBz",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
